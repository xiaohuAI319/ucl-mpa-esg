import { Folder, AIProvider, ProviderConfig } from '../types';
import { GoogleGenerativeAI } from "@google/generative-ai";

// è·å– Gemini å¯ç”¨æ¨¡å‹åˆ—è¡¨
export const listGeminiModels = async (apiKey: string): Promise<string[]> => {
  if (!apiKey) return [];
  
  try {
    // ä½¿ç”¨æ­£ç¡®çš„ REST API è·å–æ¨¡å‹åˆ—è¡¨
    const response = await fetch(`https://generativelanguage.googleapis.com/v1/models?key=${apiKey}`);
    
    if (!response.ok) {
      throw new Error(`Failed to fetch models: ${response.status}`);
    }
    
    const data = await response.json();
    
    // è¿‡æ»¤å‡ºæ”¯æŒ generateContent çš„æ¨¡å‹
    const availableModels = data.models
      ?.filter((model: any) => 
        model.supportedGenerationMethods?.includes('generateContent')
      )
      .map((model: any) => {
        // ç§»é™¤ "models/" å‰ç¼€
        const name = model.name.replace('models/', '');
        return name;
      })
      .sort() || []; // æŒ‰å­—æ¯æ’åº
    
    console.log('âœ… Gemini å¯ç”¨æ¨¡å‹:', availableModels);
    return availableModels;
    
  } catch (error) {
    console.error('âŒ è·å– Gemini æ¨¡å‹åˆ—è¡¨å¤±è´¥:', error);
    return []; // é™é»˜å¤±è´¥ï¼Œè¿”å›ç©ºæ•°ç»„
  }
};

// é»˜è®¤ç³»ç»Ÿæç¤ºè¯ï¼ˆä»…ä½œä¸ºå¤‡ç”¨ï¼Œä¼˜å…ˆä½¿ç”¨é…ç½®ä¸­çš„æç¤ºè¯ï¼‰
export const DEFAULT_SYSTEM_PROMPT = `You are an academic assistant for a UCL MPA (ESG) student.

Analyze questions from an academic policy perspective, focusing on:
- Environmental, Social, and Governance (ESG) frameworks
- Public policy analysis
- Institutional perspectives
- Evidence-based recommendations

Use the provided notes context to ground your answers. Maintain an academic tone while being helpful and clear.`;

export const collectFileContext = (folders: Folder[], maxChars = 8000): string => {
  const pieces: string[] = [];
  let used = 0;
  
  for (const folder of folders) {
    for (const file of folder.files) {
      if (!file.isText || !file.content) continue;
      if (used >= maxChars) break;
      
      const header = `ã€${folder.name} / ${file.name}ã€‘\n`;
      const remaining = maxChars - used - header.length;
      if (remaining <= 0) break;
      
      const snippet = file.content.slice(0, remaining);
      pieces.push(header + snippet);
      used += header.length + snippet.length + 2;
    }
    if (used >= maxChars) break;
  }
  
  return pieces.join('\n\n');
};

interface GenerationResult {
  text: string;
  groundingMetadata?: any;
}

export const generateResponse = async (
  question: string,
  context: string,
  provider: AIProvider,
  config: ProviderConfig,
  useSearch: boolean = false,
  customSystemPrompt?: string
): Promise<GenerationResult> => {
  
  // ä¼˜å…ˆä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤æç¤ºè¯
  const systemPrompt = customSystemPrompt || DEFAULT_SYSTEM_PROMPT;
  const fullPrompt = `User question:\n${question}\n\nNotes context:\n${context || '[No notes available]'}`;

  // Gemini Handler
  if (provider === 'gemini' && config.apiKey) {
    try {
      const genAI = new GoogleGenerativeAI(config.apiKey);
      const modelName = config.model || 'gemini-1.5-flash';
      
      const model = genAI.getGenerativeModel({
        model: modelName,
        systemInstruction: systemPrompt,
      });

      // é…ç½®ç”Ÿæˆå‚æ•°
      const generationConfig = {
        temperature: 0.7,
        topP: 0.95,
        topK: 64,
        maxOutputTokens: 8192,
      };

      // å¦‚æœå¯ç”¨æœç´¢ï¼Œä½¿ç”¨ code_execution ä»£æ›¿ï¼ˆGoogle Search éœ€è¦ç‰¹æ®Šæƒé™ï¼‰
      // æ³¨æ„ï¼šGoogle Search åŠŸèƒ½éœ€è¦ Gemini API çš„ç‰¹æ®Šè®¿é—®æƒé™
      let result;
      if (useSearch) {
        // å°è¯•ä½¿ç”¨ Google Searchï¼Œå¦‚æœå¤±è´¥åˆ™å›é€€åˆ°æ™®é€šæ¨¡å¼
        try {
          result = await model.generateContent({
            contents: [{ role: 'user', parts: [{ text: fullPrompt }] }],
            generationConfig,
          });
          
          // å¦‚æœéœ€è¦ç½‘ç»œæœç´¢ï¼Œåœ¨æç¤ºä¸­æ˜ç¡®è¯´æ˜
          if (result.response.text().includes('search') || result.response.text().includes('æŸ¥æ‰¾')) {
            const searchPrompt = `${fullPrompt}\n\nâš ï¸ æ³¨æ„ï¼šè¯·åŸºäºä½ çš„çŸ¥è¯†å›ç­”ã€‚å¦‚æœä¿¡æ¯å¯èƒ½è¿‡æ—¶ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚`;
            result = await model.generateContent({
              contents: [{ role: 'user', parts: [{ text: searchPrompt }] }],
              generationConfig,
            });
          }
        } catch (searchError) {
          console.warn('âš ï¸ Google Search åŠŸèƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨æ ‡å‡†æ¨¡å¼:', searchError);
          result = await model.generateContent({
            contents: [{ role: 'user', parts: [{ text: fullPrompt }] }],
            generationConfig,
          });
        }
      } else {
        result = await model.generateContent({
          contents: [{ role: 'user', parts: [{ text: fullPrompt }] }],
          generationConfig,
        });
      }

      const response = result.response;
      
      return {
        text: response.text() || "No response text.",
        groundingMetadata: response.candidates?.[0]?.groundingMetadata
      };

    } catch (e: any) {
      console.error("Gemini API Error", e);
      
      // å¤„ç† 429 é€Ÿç‡é™åˆ¶é”™è¯¯
      if (e.message?.includes('429') || e.message?.includes('quota')) {
        const retryMatch = e.message.match(/retry in (\d+)/i);
        const retrySeconds = retryMatch ? parseInt(retryMatch[1]) : 60;
        throw new Error(`â° Gemini è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç­‰å¾… ${retrySeconds} ç§’åé‡è¯•\n\nğŸ’¡ å»ºè®®ï¼šåˆ‡æ¢åˆ° DeepSeek æˆ– OpenAI æ¨¡å‹`);
      }
      
      throw new Error(`Gemini Error: ${e.message}`);
    }
  }

  // OpenAI / DeepSeek Handler
  if ((provider === 'openai' || provider === 'deepseek') && config.baseUrl && config.apiKey) {
    try {
      const response = await fetch(config.baseUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${config.apiKey}`
        },
        body: JSON.stringify({
          model: config.model,
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: fullPrompt }
          ],
        })
      });

      if (!response.ok) {
        const errText = await response.text();
        throw new Error(`API Error (${provider}): ${response.status} ${errText}`);
      }

      const data = await response.json();
      const content = data.choices?.[0]?.message?.content || "No response content.";
      
      return { text: content };

    } catch (e: any) {
      console.error("OpenAI/DeepSeek API Error", e);
      throw new Error(e.message);
    }
  }

  // Fallback Mock Handler
  return { text: generateMockResponse(context) };
};

const generateMockResponse = (context: string): string => {
  const hasContext = context.length > 0;
  
  return `
**Academic Analysis (Demo Mode)** ğŸ»

Based on your notes (${hasContext ? 'content detected âœ“' : 'no notes available'}), here's an academic perspective:

**Policy Context**
From a UCL MPA (ESG) standpoint, the question intersects with environmental governance, social equity, and institutional frameworks.

**Key Considerations**
- Multi-stakeholder governance
- Evidence-based policy design
- Distributional impacts
- Institutional capacity

**Recommendations**
1. Conduct stakeholder analysis
2. Review comparative policy cases
3. Assess implementation feasibility
4. Consider justice dimensions

---
*Demo Mode Active. Configure AI API keys in Settings to unlock full analysis.*
`;
};
